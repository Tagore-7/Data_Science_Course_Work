{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd40354d",
   "metadata": {},
   "source": [
    "# P4B - Learning\n",
    "\n",
    "This project give you experience with SQL and Learning topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ba6904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(5550)\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e7a12",
   "metadata": {},
   "source": [
    "# Problem: Classification - Music Hits \n",
    "\n",
    "For this problem, you will work to classify a song’s popularity. Specifically, you will develop methods to predict whether a song will make the Top10 of Billboard’s Hot 100 Chart. The data set consists of song from the Top10 of Billboard’s Hot 100 Chart from 1990-2010 along with a sampling of other songs that did not make the list.  \n",
    "\n",
    "The data source is adapted from one used in a MIT 15.071 course. The data set was created by scraping Billboard’s Hot 100, other songs on Billboard, and using the EchoNest API, now a part of Spotify, to get song information.\n",
    "\n",
    "The variables included in the data set include several description of the song and artist (including song title and id numbers), the year the song was released. Additionally, several variables describe the song attributes: time signature, loudness, tempo, key, energy pitch, and timbre (measured of different sections of the song). The last variable is binary indicated whether the song was in the Top10 or not.\n",
    "\n",
    "You will use the variables of the song attributes to predict whether the song will be popular or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2724ae3",
   "metadata": {},
   "source": [
    "## Q1 - Load and understand the data \n",
    "\n",
    "Load in the `music` data. \n",
    "\n",
    "You should not use the `year`, `artistname`, `artistID`, `songtitle` or `songID` in the prediction.  \n",
    "Additionally, remove any variables that are the confidence of another variable, e.g., `timesignature_confidence`, `temp_confidence`. \n",
    "\n",
    "\n",
    "Create a input feature matrix, `Xm` and label vector `ym` that you will use to create your classifiers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e95759f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m music \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusic-f23.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m drop_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martistname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martistID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimesignature_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtempo_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m music \u001b[38;5;241m=\u001b[39m music\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m drop_columns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "music = pd.read_csv('music-f23.csv', encoding = \"ISO-8859-1\")\n",
    "drop_columns = ['year', 'artistname', 'artistID', 'songtitle', 'songID','timesignature_confidence','tempo_confidence','key_confidence']\n",
    "music = music.drop(columns = drop_columns)\n",
    "\n",
    "Xm = music.drop(columns = ['Top10'])\n",
    "ym = music['Top10']\n",
    "\n",
    "Xm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d5b31f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2dc47",
   "metadata": {},
   "source": [
    "## Q2. Classify Top 10 Hits \n",
    "\n",
    "We want to report out the results of predicting the top-10 hits using either KNN, Decision Trees, or SVMS.  \n",
    "\n",
    "For each model, you will tune the hyper-parameters:    \n",
    "* KNN, number of neighbors = [3, 5, 7, 9, 11] and weights = ['uniform', 'distance']\n",
    "* Decision Trees, maximum depth of the tree = [2, 5, 10, 15] and criterion of ['gini', 'entropy'], set the random_state = 5\n",
    "* SVM, use a rbf kernel with C = [0.01, 0.1, 1, 10] \n",
    "\n",
    "In addition, you will want to see which scaling methods seems to work best for this dataset and method: `StandardScaler` or `MinMaxScaler`. \n",
    "\n",
    "Overall, you will construct **three pipelines** to perform this analysis one for each model: KNN, DT, SVM.  You will do an initial stratified split of your data into training+validation set with 85% of the data and a test set with 15% of the data (random_state=5).  Use 10-fold stratified cross-validation with a random_state = 5. \n",
    "\n",
    "Additionally, when selecting the best hyper-parameters, instead of using accuracy you will use the `f1_measure`.  \n",
    " \n",
    "The steps in your pipeline should be called `scaler` for the scaling step, `knn` for the KNN classifier, `dt` for the Decision Tree, and `svm` for the Support Vector Machine. \n",
    "\n",
    "One note, we are not using the results here to select a certain model (that would be using the test set for more than just estimating the generalized performance), rather just to report out the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9306e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split of the test set \n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(Xm, ym, test_size = 0.15, random_state = 5, stratify = ym)\n",
    "\n",
    "\n",
    "\n",
    "# ** KNN **\n",
    "# Create pipeline, with steps 'scaler' and 'knn'\n",
    "knn_pipe = Pipeline( [('scaler', StandardScaler()),  ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# specify pipeline steps hyperparameters\n",
    "knn_param = { 'knn__n_neighbors': [3, 5, 7, 9, 11], 'knn__weights': ['uniform', 'distance']}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_param, cv=cvStrat, scoring='f1', n_jobs=-1)\n",
    "knn_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "\n",
    "# preditions on final test set \n",
    "knn_ytest = knn_grid.predict(X_test)\n",
    "\n",
    "\n",
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc68908d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__criterion': 'gini', 'dt__max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(5550)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ** DT ** \n",
    "# Create pipeline, with steps 'scaler' and 'dt'\n",
    "dt_pipe = Pipeline([('scaler', StandardScaler()), ('dt', DecisionTreeClassifier(random_state=5))])\n",
    "\n",
    "dt_param = { 'dt__max_depth': [2, 5, 10, 15],'dt__criterion': ['gini', 'entropy']}  \n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat =  StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "dt_grid =GridSearchCV(dt_pipe, dt_param, cv=cvStrat, scoring='f1', n_jobs=-1)\n",
    "dt_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set \n",
    "dt_ytest = dt_grid.predict(X_test)\n",
    "\n",
    "\n",
    "print(dt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a4c9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# ** SVM ** \n",
    "# Create pipeline, with steps 'scaler' and 'svm'\n",
    "svm_pipe = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf'))])\n",
    "\n",
    "svm_param =  {'svm__C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "svm_grid = GridSearchCV(svm_pipe, svm_param, cv=cvStrat, scoring='f1', n_jobs=-1)\n",
    "svm_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set\n",
    "svm_ytest = svm_grid.predict(X_test)\n",
    "\n",
    "\n",
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82487a58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9345595",
   "metadata": {},
   "source": [
    "## Q3  Table of Results \n",
    "\n",
    "Report in a DataFrame the following information for each model:\n",
    "* `Model` type (KNN, DT, SVM), \n",
    "* best `Hyper-parameters` for the model, e.g., [(n_neighbors, 7), (weights, 'uniform')], (max_depth, 10), ('C', 0.1), etc.\n",
    "* `Accuracy`, \n",
    "* `Precision`,\n",
    "* `Recall`, \n",
    "* `F1-measure` and \n",
    "* `Balanced Acc` - balanced accuracy\n",
    "\n",
    "The last 5 values should all be calculated on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0e8edd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Hyper-parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-measure</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__weights': 'dista...</td>\n",
       "      <td>0.741158</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.398810</td>\n",
       "      <td>0.454237</td>\n",
       "      <td>0.633325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 10}</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.392638</td>\n",
       "      <td>0.586952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'svm__C': 10}</td>\n",
       "      <td>0.747588</td>\n",
       "      <td>0.539568</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.488599</td>\n",
       "      <td>0.652730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model                                   Hyper-parameters  Accuracy  \\\n",
       "0            KNN  {'knn__n_neighbors': 3, 'knn__weights': 'dista...  0.741158   \n",
       "1  Decision Tree     {'dt__criterion': 'gini', 'dt__max_depth': 10}  0.681672   \n",
       "2            SVM                                     {'svm__C': 10}  0.747588   \n",
       "\n",
       "   Precision    Recall  F1-measure  Balanced Acc.  \n",
       "0   0.527559  0.398810    0.454237       0.633325  \n",
       "1   0.405063  0.380952    0.392638       0.586952  \n",
       "2   0.539568  0.446429    0.488599       0.652730  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build data frame of requested results\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_ytest)\n",
    "knn_precision = precision_score(y_test, knn_ytest)\n",
    "knn_recall = recall_score(y_test, knn_ytest)\n",
    "knn_f1 = f1_score(y_test, knn_ytest)\n",
    "knn_balanced_acc = balanced_accuracy_score(y_test, knn_ytest)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_ytest)\n",
    "dt_precision = precision_score(y_test, dt_ytest)\n",
    "dt_recall = recall_score(y_test, dt_ytest)\n",
    "dt_f1 = f1_score(y_test, dt_ytest)\n",
    "dt_balanced_acc = balanced_accuracy_score(y_test, dt_ytest)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm_ytest)\n",
    "svm_precision = precision_score(y_test, svm_ytest)\n",
    "svm_recall = recall_score(y_test, svm_ytest)\n",
    "svm_f1 = f1_score(y_test, svm_ytest)\n",
    "svm_balanced_acc = balanced_accuracy_score(y_test, svm_ytest)\n",
    "\n",
    "# Create DataFrame\n",
    "results_data = {\n",
    "    'Model': ['KNN', 'Decision Tree', 'SVM'],\n",
    "    'Hyper-parameters': [knn_grid.best_params_, dt_grid.best_params_, svm_grid.best_params_],\n",
    "    'Accuracy': [knn_accuracy, dt_accuracy, svm_accuracy],\n",
    "    'Precision': [knn_precision, dt_precision, svm_precision],\n",
    "    'Recall': [knn_recall, dt_recall, svm_recall],\n",
    "    'F1-measure': [knn_f1, dt_f1, svm_f1],\n",
    "    'Balanced Acc.': [knn_balanced_acc, dt_balanced_acc, svm_balanced_acc]\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(results_data)\n",
    "\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e658c22b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c65ad1",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q4  Results summary \n",
    "\n",
    "Describe the results.  Write 5-7 sentences about the results observed and the overall performance on the problem.  Include a description of which method does best of predicting the positive examples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e62cc7",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "The results indicate that the Support Vector Machine (SVM) model performs the best among the three models (KNN, Decision Tree, SVM) in predicting whether a song will make it to the Top 10 of Billboard's Hot 100 Chart. The SVM model has the highest accuracy, precision, recall, and F1-measure on the test set. The SVM model with a C value of 10 outperformed other hyperparameter combinations.\n",
    "\n",
    "The KNN model showed slightly lower performance compared to SVM. The distance-weighted approach with three neighbors worked well for this classification task.\n",
    "\n",
    "The Decision Tree model, falls slightly behind the SVM and KNN models. The chosen hyperparameters for the Decision Tree, with a criterion of 'gini' and a max depth of 10, represented a good balance between complexity and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c188e67",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Bonus.  Improve Performance of Models\n",
    "\n",
    "The problem we are working with deals with an imbalanced data set.  Meaning there are many more of one class than the other.  For this dataset, ~77% of the data are negative samples (not Top10 hits). \n",
    "\n",
    "The imbalanced data is one explanation for the poor performance of our classifiers above (among other reasons).  \n",
    "\n",
    "Let's try to improve this performance.  Classification with imbalanced data can be improved using a number of different techniques.  Two approaches are: \n",
    "\n",
    "* Cost-sensitive or weighted learning approach\n",
    "* Data or sampling approach \n",
    "\n",
    "Here we will examing the class weighting approach. Some of our traditional classification models are adapted to include a penalty of cost for the different classes.  In our problem, we have a minority class \"Top10 Hits\" and the majority class \"Non-Top10 Hits\".  We can use class weighting to penalize the model for misclassifying the minority class more than the majority class.  \n",
    "\n",
    "We will make use of the `scikit-learn` parameter `class_weight`.  Setting `class_weight ='balanced'` will have a weight applied inversely proportional to the class frequency.  \n",
    "\n",
    "Note, not all classification models have this parameter to set, e.g., KNN. \n",
    "\n",
    "Rerun your DT and SVM pipelines from above (Q2) now with the DT and SVM using the parameter `class_weight ='balanced'`\n",
    "\n",
    "Add the resulting models `DT bal class weights` and `SVM bal class weights` and their performance to the results table from Q3.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc7749c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__criterion': 'entropy', 'dt__max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ** DT ** \n",
    "# include class_weight in DT parameters\n",
    "dt_pipe2 = Pipeline([('scaler', StandardScaler()), ('dt', DecisionTreeClassifier(random_state=5, class_weight='balanced'))])\n",
    "\n",
    "# Specify DT hyperparameters\n",
    "dt_param2 = {'dt__max_depth': [2, 5, 10, 15], 'dt__criterion': ['gini', 'entropy']}   \n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "dt_grid2 = GridSearchCV(dt_pipe2, param_grid=dt_param2, cv=cvStrat, scoring='f1', n_jobs=-1)\n",
    "dt_grid2.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set \n",
    "dt_ytest2 = dt_grid2.predict(X_test)\n",
    "\n",
    "\n",
    "print(dt_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ca660b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm__C': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ** SVM ** \n",
    "# include class_weight in SVM parameters\n",
    "svm_pipe2 =  Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf', class_weight='balanced'))])\n",
    "\n",
    "\n",
    "# Specify SVM hyperparameters\n",
    "svm_param2 = {'svm__C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "svm_grid2 = GridSearchCV(svm_pipe2, param_grid=svm_param2, cv=cvStrat, scoring='f1', n_jobs=-1)\n",
    "svm_grid2.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set\n",
    "svm_ytest2 = svm_grid2.predict(X_test)\n",
    "\n",
    "\n",
    "print(svm_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2355be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Hyper-parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-measure</th>\n",
       "      <th>Balanced Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'knn__n_neighbors': 3, 'knn__weights': 'dista...</td>\n",
       "      <td>0.741158</td>\n",
       "      <td>0.527559</td>\n",
       "      <td>0.398810</td>\n",
       "      <td>0.454237</td>\n",
       "      <td>0.633325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 10}</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.392638</td>\n",
       "      <td>0.586952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'svm__C': 10}</td>\n",
       "      <td>0.747588</td>\n",
       "      <td>0.539568</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.488599</td>\n",
       "      <td>0.652730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT bal class weights</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': 5}</td>\n",
       "      <td>0.602894</td>\n",
       "      <td>0.377709</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.496945</td>\n",
       "      <td>0.641730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM bal class weights</td>\n",
       "      <td>{'svm__C': 1}</td>\n",
       "      <td>0.731511</td>\n",
       "      <td>0.502203</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.577215</td>\n",
       "      <td>0.714836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                   Hyper-parameters  \\\n",
       "0                    KNN  {'knn__n_neighbors': 3, 'knn__weights': 'dista...   \n",
       "1          Decision Tree     {'dt__criterion': 'gini', 'dt__max_depth': 10}   \n",
       "2                    SVM                                     {'svm__C': 10}   \n",
       "3   DT bal class weights   {'dt__criterion': 'entropy', 'dt__max_depth': 5}   \n",
       "4  SVM bal class weights                                      {'svm__C': 1}   \n",
       "\n",
       "   Accuracy  Precision    Recall  F1-measure  Balanced Acc.  \n",
       "0  0.741158   0.527559  0.398810    0.454237       0.633325  \n",
       "1  0.681672   0.405063  0.380952    0.392638       0.586952  \n",
       "2  0.747588   0.539568  0.446429    0.488599       0.652730  \n",
       "3  0.602894   0.377709  0.726190    0.496945       0.641730  \n",
       "4  0.731511   0.502203  0.678571    0.577215       0.714836  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Add \"DT balanced class weights\" and \"SVM balanced class weights\" rows \n",
    "#  to the results table. \n",
    "\n",
    "\n",
    "dt2_accuracy = accuracy_score(y_test, dt_ytest2)\n",
    "dt2_precision = precision_score(y_test, dt_ytest2)\n",
    "dt2_recall = recall_score(y_test, dt_ytest2)\n",
    "dt2_f1 = f1_score(y_test, dt_ytest2)\n",
    "dt2_balanced_acc = balanced_accuracy_score(y_test, dt_ytest2)\n",
    "\n",
    "svm2_accuracy = accuracy_score(y_test, svm_ytest2)\n",
    "svm2_precision = precision_score(y_test, svm_ytest2)\n",
    "svm2_recall = recall_score(y_test, svm_ytest2)\n",
    "svm2_f1 = f1_score(y_test, svm_ytest2)\n",
    "svm2_balanced_acc = balanced_accuracy_score(y_test, svm_ytest2)\n",
    "\n",
    "# Create DataFrame\n",
    "results2_data = {\n",
    "    'Model': [ 'DT bal class weights', 'SVM bal class weights'],\n",
    "    'Hyper-parameters': [dt_grid2.best_params_, svm_grid2.best_params_],\n",
    "    'Accuracy': [dt2_accuracy, svm2_accuracy],\n",
    "    'Precision': [dt2_precision, svm2_precision],\n",
    "    'Recall': [dt2_recall, svm2_recall],\n",
    "    'F1-measure': [dt2_f1, svm2_f1],\n",
    "    'Balanced Acc.': [dt2_balanced_acc, svm2_balanced_acc]\n",
    "}\n",
    "\n",
    "results2 = pd.DataFrame(results2_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = pd.concat([results, results2], ignore_index= True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c813e05",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>bonus</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "bonus results: All test cases passed!"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44351fa1-a092-4650-8e3a-67a7643e4202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e1cca",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Bonus 2 \n",
    "\n",
    "Given the update results.  State which classifier you would want to use to ensure that you correctly identified the most Top10 Hits.  Explain why (briefly 1-2 sentences). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5835e",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "Based on the above results, the SVM model with balanced class weights is the best classifier for identifying the most Top10 Hits. It has the highest balanced accuracy (0.714836) among the other models, indicating a good trade-off between precision and recall. This means it is better at correctly identifying positive examples while also minimizing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19bd57",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b8898",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3a8b9f62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <p>\n",
       "                        Your submission has been exported. Click\n",
       "                        <a href=\"p4b_2023_11_22T17_41_46_550514.zip\" download=\"p4b_2023_11_22T17_41_46_550514.zip\" target=\"_blank\">here</a> to download\n",
       "                        the zip file.\n",
       "                    </p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceef5ff",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-un5550] *",
   "language": "python",
   "name": "conda-env-.conda-un5550-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p4b",
   "tests": {
    "bonus": {
     "name": "bonus",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> results.shape == (5, 7)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xm.shape == (4142,30)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> ym.shape[0] == 4142\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(Xm.columns == ['timesignature', 'loudness', 'tempo', 'key', 'energy', 'pitch',\n...        'timbre_0_min', 'timbre_0_max', 'timbre_1_min', 'timbre_1_max',\n...        'timbre_2_min', 'timbre_2_max', 'timbre_3_min', 'timbre_3_max',\n...        'timbre_4_min', 'timbre_4_max', 'timbre_5_min', 'timbre_5_max',\n...        'timbre_6_min', 'timbre_6_max', 'timbre_7_min', 'timbre_7_max',\n...        'timbre_8_min', 'timbre_8_max', 'timbre_9_min', 'timbre_9_max',\n...        'timbre_10_min', 'timbre_10_max', 'timbre_11_min', 'timbre_11_max'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(ym.value_counts() == [3024, 1118])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 24,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> knn_grid.best_params_['knn__n_neighbors'] == 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> results.shape == (3,7)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(results.columns == ['Model', 'Hyper-parameters', 'Accuracy', 'Precision', \n...                     'Recall', 'F1-measure', 'Balanced Acc.'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
